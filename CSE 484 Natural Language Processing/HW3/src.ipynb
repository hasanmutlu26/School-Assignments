{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 310,
      "metadata": {},
      "outputs": [],
      "source": [
        "from nltk import ngrams\n",
        "\n",
        "\n",
        "unigram_table = {}\n",
        "\n",
        "def createUnigram():\n",
        "    global unigram_table\n",
        "    def create_unigram_table(text_data, unigram_table):\n",
        "        \n",
        "        unigrams = list(ngrams(text_data.split(), 1))\n",
        "        for unigram in unigrams:\n",
        "            if unigram in unigram_table:\n",
        "                unigram_table[unigram] += 1\n",
        "            else:\n",
        "                unigram_table[unigram] = 1\n",
        "        return unigram_table\n",
        "\n",
        "    def read_text_data(file):\n",
        "        \n",
        "        for line in file:\n",
        "            yield line\n",
        "\n",
        "\n",
        "\n",
        "    with open(\"syllables95.txt\") as f:\n",
        "        for line in read_text_data(f):\n",
        "            unigram_table = create_unigram_table(line, unigram_table)\n",
        "\n",
        "\n",
        "    with open(\"unigram_table.txt\", \"w\") as f:\n",
        "        for unigram, count in unigram_table.items():\n",
        "            f.write(f\"{unigram}: {count}\\n\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 311,
      "metadata": {},
      "outputs": [],
      "source": [
        "bigram_table = {}\n",
        "\n",
        "def createBigram():\n",
        "    global bigram_table\n",
        "    def create_bigram_table(text_data, bigram_table):\n",
        "        \n",
        "        bigrams = list(ngrams(text_data.split(), 2))\n",
        "        for bigram in bigrams:\n",
        "            if bigram in bigram_table:\n",
        "                bigram_table[bigram] += 1\n",
        "            else:\n",
        "                bigram_table[bigram] = 1\n",
        "        return bigram_table\n",
        "\n",
        "    def read_text_data(file):\n",
        "        \n",
        "        for line in file:\n",
        "            yield line\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "    with open(\"syllables95.txt\") as f:\n",
        "        for line in read_text_data(f):\n",
        "            bigram_table = create_bigram_table(line, bigram_table)\n",
        "\n",
        "    with open(\"bigram_table.txt\", \"w\") as f:\n",
        "        for bigram, count in bigram_table.items():\n",
        "            f.write(f\"{bigram}: {count}\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 312,
      "metadata": {},
      "outputs": [],
      "source": [
        "trigram_table = {}\n",
        "\n",
        "def createTrigram():\n",
        "    global trigram_table\n",
        "    def create_trigram_table(text_data, trigram_table):\n",
        "        trigrams = list(ngrams(text_data.split(), 3))\n",
        "        for trigram in trigrams:\n",
        "            if trigram in trigram_table:\n",
        "                trigram_table[trigram] += 1\n",
        "            else:\n",
        "                trigram_table[trigram] = 1\n",
        "        return trigram_table\n",
        "\n",
        "    def read_text_data(file):\n",
        "        for line in file:\n",
        "            yield line\n",
        "\n",
        "    \n",
        "\n",
        "    with open(\"syllables95.txt\") as f:\n",
        "        for line in read_text_data(f):\n",
        "            trigram_table = create_trigram_table(line, trigram_table)\n",
        "\n",
        "    with open(\"trigram_table.txt\", \"w\") as f:\n",
        "        for trigram, count in trigram_table.items():\n",
        "            f.write(f\"{trigram}: {count}\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 313,
      "metadata": {},
      "outputs": [],
      "source": [
        "import gensim\n",
        "\n",
        "def create_word2vec_model(n_gram_table):\n",
        "    n_grams = [[word for word in n_gram] for n_gram in n_gram_table.keys()]\n",
        "\n",
        "    model = gensim.models.Word2Vec(n_grams, vector_size=100, window=5, min_count=1, workers=8)\n",
        "    return model\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 314,
      "metadata": {},
      "outputs": [],
      "source": [
        "def ngram2Vec():\n",
        "    unigram_model = create_word2vec_model(unigram_table)\n",
        "    bigram_model = create_word2vec_model(bigram_table)\n",
        "    trigram_model = create_word2vec_model(trigram_table)\n",
        "\n",
        "    unigram_model.save(\"unigram_model.bin\")\n",
        "\n",
        "    bigram_model.save(\"bigram_model.bin\")\n",
        "\n",
        "    trigram_model.save(\"trigram_model.bin\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 315,
      "metadata": {},
      "outputs": [],
      "source": [
        "import gensim.models.word2vec\n",
        "\n",
        "def read_models_from_files():\n",
        "    global unigram_model\n",
        "    global bigram_model\n",
        "    global trigram_model\n",
        "\n",
        "    unigram_model = gensim.models.word2vec.Word2Vec.load(\"unigram_model.bin\")\n",
        "\n",
        "    bigram_model = gensim.models.word2vec.Word2Vec.load(\"bigram_model.bin\")\n",
        "\n",
        "    trigram_model = gensim.models.word2vec.Word2Vec.load(\"trigram_model.bin\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 316,
      "metadata": {},
      "outputs": [],
      "source": [
        "from scipy.stats import pearsonr\n",
        "\n",
        "def most_similar_pairs(syl1, syl2, model):\n",
        "    vec_syl12 = bigram_model.wv.get_vector(syl1) - bigram_model.wv.get_vector(syl2)\n",
        "\n",
        "\n",
        "    vocab = bigram_model.wv.index_to_key \n",
        "\n",
        "    # Initialize a list to store the most similar word pairs\n",
        "    most_similar_pairs = []\n",
        "\n",
        "    # Iterate through all pairs of words in the vocabulary\n",
        "    for word1 in vocab:\n",
        "        for word2 in vocab:\n",
        "            # Calculate the difference vector between the two words\n",
        "            difference_vector = bigram_model.wv.get_vector(word1) - bigram_model.wv.get_vector(word2)\n",
        "            \n",
        "            # Calculate the similarity between the difference vector and vec_la_ri\n",
        "            similarity, p_value = pearsonr(difference_vector, vec_syl12)\n",
        "            \n",
        "            # If the similarity is high, add the word pair to the list of most similar pairs\n",
        "            if similarity > 0.95:\n",
        "                most_similar_pairs.append((word1, word2, similarity))\n",
        "\n",
        "    # Sort the list of most similar pairs by similarity in descending order\n",
        "    most_similar_pairs.sort(key=lambda x: x[2], reverse=True)\n",
        "\n",
        "    # Print the most similar word pairs and their similarity scores\n",
        "    for word1, word2, similarity in most_similar_pairs:\n",
        "        print(f\"{word1} - {word2}: {similarity}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 317,
      "metadata": {},
      "outputs": [],
      "source": [
        "def similarity_test(syl1, syl2, syl3, syl4):\n",
        "    print(f\"Similarity between {syl1}-{syl2} and {syl3}-{syl4}: \")\n",
        "\n",
        "    vec_syl1 = unigram_model.wv.get_vector(syl1) - unigram_model.wv.get_vector(syl2)\n",
        "    vec_syl2 = unigram_model.wv.get_vector(syl3) - unigram_model.wv.get_vector(syl4)\n",
        "\n",
        "    similarity, p_value = pearsonr(vec_syl1, vec_syl2)\n",
        "\n",
        "    print(\"Unigram: \" + str(similarity))\n",
        "\n",
        "    vec_syl1 = bigram_model.wv.get_vector(syl1) - bigram_model.wv.get_vector(syl2)\n",
        "    vec_syl2 = bigram_model.wv.get_vector(syl3) - bigram_model.wv.get_vector(syl4)\n",
        "\n",
        "    similarity, p_value = pearsonr(vec_syl1, vec_syl2)\n",
        "\n",
        "    print(\"Bigram: \" + str(similarity))\n",
        "\n",
        "    vec_syl1 = trigram_model.wv.get_vector(syl1) - trigram_model.wv.get_vector(syl2)\n",
        "    vec_syl2 = trigram_model.wv.get_vector(syl3) - trigram_model.wv.get_vector(syl4)\n",
        "\n",
        "    similarity, p_value = pearsonr(vec_syl1, vec_syl2)\n",
        "\n",
        "    print(\"Trigram: \" + str(similarity), end=\"\\n\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 318,
      "metadata": {},
      "outputs": [],
      "source": [
        "def similarity_test_2(syl1, syl2, syl3, syl4, syl5, syl6):\n",
        "    print(f\"Similarity between {syl1}-{syl2}-{syl3} and {syl4}-{syl5}-{syl6}\")\n",
        "    vec_syl1 = unigram_model.wv.get_vector(syl1) - unigram_model.wv.get_vector(syl2) - unigram_model.wv.get_vector(syl3)\n",
        "    vec_syl2 = unigram_model.wv.get_vector(syl4) - unigram_model.wv.get_vector(syl5) - unigram_model.wv.get_vector(syl6)\n",
        "\n",
        "    similarity, p_value = pearsonr(vec_syl1, vec_syl2)\n",
        "    print(\"Unigram \" + str(similarity))\n",
        "\n",
        "    vec_syl1 = bigram_model.wv.get_vector(syl1) - bigram_model.wv.get_vector(syl2) - bigram_model.wv.get_vector(syl3)\n",
        "    vec_syl2 = bigram_model.wv.get_vector(syl4) - bigram_model.wv.get_vector(syl5) - bigram_model.wv.get_vector(syl6)\n",
        "\n",
        "    similarity, p_value = pearsonr(vec_syl1, vec_syl2)\n",
        "    print(\"Bigram \" + str(similarity))\n",
        "\n",
        "    vec_syl1 = trigram_model.wv.get_vector(syl1) - trigram_model.wv.get_vector(syl2) - trigram_model.wv.get_vector(syl3)\n",
        "    vec_syl2 = trigram_model.wv.get_vector(syl4) - trigram_model.wv.get_vector(syl5) - trigram_model.wv.get_vector(syl6)\n",
        "\n",
        "    similarity, p_value = pearsonr(vec_syl1, vec_syl2)\n",
        "    print(\"Trigram \" + str(similarity), end=\"\\n\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 319,
      "metadata": {},
      "outputs": [],
      "source": [
        "def similar_syllables(syl):\n",
        "    print(\"Similar syllables to \" + syl + \":\")\n",
        "\n",
        "    similar_pairs = unigram_model.wv.most_similar(syl, topn=3)\n",
        "\n",
        "    # Print the most similar word pairs and their similarity scores\n",
        "    print(\"Unigram: \")\n",
        "    for word, similarity in similar_pairs:\n",
        "        print(f\"{word}: {similarity}\")\n",
        "\n",
        "    similar_pairs = bigram_model.wv.most_similar(syl, topn=3)\n",
        "\n",
        "    # Print the most similar word pairs and their similarity scores\n",
        "    print(\"Bigram: \")\n",
        "    for word, similarity in similar_pairs:\n",
        "        print(f\"{word}: {similarity}\")\n",
        "\n",
        "    similar_pairs = trigram_model.wv.most_similar(syl, topn=3)\n",
        "\n",
        "    # Print the most similar word pairs and their similarity scores\n",
        "    print(\"Trigram: \")\n",
        "    for word, similarity in similar_pairs:\n",
        "        print(f\"{word}: {similarity}\")\n",
        "\n",
        "    print(\"\\n\")\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 325,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---\n",
            "Part 4: Find similar syllables\n",
            "---\n",
            "ri from odalari\n",
            "Similar syllables to ri:\n",
            "Unigram: \n",
            "yaz: 0.2998822331428528\n",
            "mog: 0.2973637878894806\n",
            "ark: 0.29700127243995667\n",
            "Bigram: \n",
            "ra: 0.9984901547431946\n",
            "te: 0.9983323216438293\n",
            "re: 0.9983175992965698\n",
            "Trigram: \n",
            "ni: 0.7476686835289001\n",
            "re: 0.6885415315628052\n",
            "ra: 0.6720702648162842\n",
            "\n",
            "\n",
            "ler from geldiler\n",
            "Similar syllables to ler:\n",
            "Unigram: \n",
            "mond: 0.37578514218330383\n",
            "ik: 0.32739895582199097\n",
            "cit: 0.30533266067504883\n",
            "Bigram: \n",
            "ne: 0.9978345036506653\n",
            "lar: 0.9975080490112305\n",
            "na: 0.9974647760391235\n",
            "Trigram: \n",
            "le: 0.6296705007553101\n",
            "len: 0.6084480881690979\n",
            "den: 0.5954577326774597\n",
            "\n",
            "\n",
            "de from bizdeki\n",
            "Similar syllables to de:\n",
            "Unigram: \n",
            "law: 0.33243757486343384\n",
            "ment: 0.31676486134529114\n",
            "lun: 0.29563137888908386\n",
            "Bigram: \n",
            "le: 0.9989104270935059\n",
            "e: 0.9988452792167664\n",
            "in: 0.9984219670295715\n",
            "Trigram: \n",
            "den: 0.7939417362213135\n",
            "dey: 0.6487324237823486\n",
            "e: 0.6194984912872314\n",
            "\n",
            "\n",
            "ma from almad覺\n",
            "Similar syllables to ma:\n",
            "Unigram: \n",
            "dri: 0.2908521592617035\n",
            "miss: 0.28723376989364624\n",
            "mak: 0.2812935411930084\n",
            "Bigram: \n",
            "ka: 0.9988505244255066\n",
            "se: 0.9985846281051636\n",
            "ha: 0.9983826279640198\n",
            "Trigram: \n",
            "mam: 0.7047206163406372\n",
            "maz: 0.6466859579086304\n",
            "mi: 0.6438233256340027\n",
            "\n",
            "\n",
            "yan from almayan\n",
            "Similar syllables to yan:\n",
            "Unigram: \n",
            "ar: 0.349456250667572\n",
            "fonk: 0.3170119822025299\n",
            "dut: 0.2954171299934387\n",
            "Bigram: \n",
            "kar: 0.9971659779548645\n",
            "is: 0.9960188269615173\n",
            "san: 0.9959636926651001\n",
            "Trigram: \n",
            "mam: 0.6464670896530151\n",
            "nav: 0.6421260237693787\n",
            "zalt: 0.638239860534668\n",
            "\n",
            "\n",
            "---\n",
            "Part 5: Morphology analogy tests\n",
            "---\n",
            "Example: odalari - odalarim\n",
            "Similarity between la-ri and la-rim: \n",
            "Unigram: 0.3826620888982762\n",
            "Bigram: 0.9313843214442574\n",
            "Trigram: 0.764169758144598\n",
            "\n",
            "Example: geldiler ald覺lar\n",
            "Similarity between di-ler and di-lar: \n",
            "Unigram: 0.5589749258710471\n",
            "Bigram: 0.8732260898959346\n",
            "Trigram: 0.34202566073552787\n",
            "\n",
            "Example: bizdeki ondaki\n",
            "Similarity between de-ki and da-ki: \n",
            "Unigram: 0.621688917015635\n",
            "Bigram: 0.9619404409295209\n",
            "Trigram: 0.6408257657395211\n",
            "\n",
            "Example: almadi vermedi\n",
            "Similarity between ma-di and me-di: \n",
            "Unigram: 0.47796887472468524\n",
            "Bigram: 0.7837718541473246\n",
            "Trigram: 0.5891222728227427\n",
            "\n",
            "Example: almayan gitmeyen\n",
            "Similarity between ma-yan and me-yen: \n",
            "Unigram: -0.037034628450270626\n",
            "Bigram: 0.9724685449719089\n",
            "Trigram: 0.5780176802748743\n",
            "\n",
            "---\n",
            "Part 5 Bonus: Word analogy tests\n",
            "---\n",
            "Similarity between a-dam and ka-din: \n",
            "Unigram: -0.02903769246442553\n",
            "Bigram: 0.995761855043015\n",
            "Trigram: 0.23656374861115007\n",
            "\n",
            "Similarity between is-pan-ya and por-te-kiz\n",
            "Unigram 0.052969018136637326\n",
            "Bigram 0.9923420827097618\n",
            "Trigram -0.005084979416491539\n",
            "\n",
            "Similarity between mer-ce-des and to-yo-ta\n",
            "Unigram -0.05553489770548663\n",
            "Bigram 0.9661288780433916\n",
            "Trigram 0.13651665939828583\n",
            "\n",
            "Similarity between as-lan and ke-di: \n",
            "Unigram: 0.09548468662384466\n",
            "Bigram: 0.8735735629092946\n",
            "Trigram: 0.11367025337928642\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n",
        "createUnigram()\n",
        "\n",
        "createBigram()\n",
        "\n",
        "createTrigram()\n",
        "\n",
        "\n",
        "ngram2Vec()\n",
        "\n",
        "\n",
        "read_models_from_files()\n",
        "\n",
        "\n",
        "print(\"---\\nPart 4: Find similar syllables\\n---\")\n",
        "\n",
        "print(\"ri from odalari\")\n",
        "similar_syllables(\"ri\")\n",
        "\n",
        "print(\"ler from geldiler\")\n",
        "similar_syllables(\"ler\")\n",
        "\n",
        "print(\"de from bizdeki\")\n",
        "similar_syllables(\"de\")\n",
        "\n",
        "print(\"ma from almad覺\")\n",
        "similar_syllables(\"ma\")\n",
        "\n",
        "print(\"yan from almayan\")\n",
        "similar_syllables(\"yan\")\n",
        "\n",
        "\n",
        "\n",
        "print(\"---\\nPart 5: Morphology analogy tests\\n---\")\n",
        "\n",
        "print(\"Example: odalari - odalarim\")\n",
        "similarity_test(\"la\", \"ri\", \"la\", \"rim\")\n",
        "\n",
        "print(\"Example: geldiler ald覺lar\")\n",
        "similarity_test(\"di\", \"ler\", \"di\", \"lar\")\n",
        "\n",
        "print(\"Example: bizdeki ondaki\")\n",
        "similarity_test(\"de\", \"ki\", \"da\", \"ki\")\n",
        "\n",
        "print(\"Example: almadi vermedi\")\n",
        "similarity_test(\"ma\", \"di\", \"me\", \"di\")\n",
        "\n",
        "print(\"Example: almayan gitmeyen\")\n",
        "similarity_test(\"ma\", \"yan\", \"me\", \"yen\")\n",
        "\n",
        "\n",
        "\n",
        "print(\"---\\nPart 5 Bonus: Word analogy tests\\n---\")\n",
        "\n",
        "similarity_test(\"a\", \"dam\", \"ka\", \"din\")\n",
        "\n",
        "similarity_test_2(\"is\", \"pan\", \"ya\", \"por\", \"te\", \"kiz\")\n",
        "\n",
        "similarity_test_2(\"mer\", \"ce\", \"des\", \"to\", \"yo\", \"ta\")\n",
        "\n",
        "similarity_test(\"as\", \"lan\", \"ke\", \"di\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
